{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e37649edaa8d0d",
   "metadata": {},
   "source": [
    "# PyMC dims module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2002b7ab9e00eb",
   "metadata": {},
   "source": [
    "## A short history of dims in PyMC\n",
    "\n",
    "PyMC introduced the ability to specify model variable `dims` in version 3.9 in June 2020 (5 years as of the time of writing). In the release notes, it was mentioned only after [14 other new features](https://github.com/pymc-devs/pymc/blob/1d00f3eb81723523968f3610e81a0c42fd96326f/RELEASE-NOTES.md?plain=1#L236), but over time it became a foundation of the library.\n",
    "\n",
    "It allows users to more naturally specify the dimensions of model variables with string names, and provides a \"seamless\" conversion to arviz :doc:`InferenceData <arviz:Xarray_for_arviz>` objects, which have become the standard for storing and investigating results from probabilistic programming languages.\n",
    "\n",
    "However, the behavior of dims is rather limited. It can only be used to specify the shape of new random variables and label existing dimensions (e.g., in :func:`~pymc.Deterministic`). Otherwise it has no effect on the computation, unlike operations done with :class:`~arviz.InferenceData` variables, which are based on :mod:`Xarray` and where dims inform array selection, alignment, and broadcasting behavior.\n",
    "\n",
    "As a result, in PyMC models users have to write computations that follow NumPy semantics, which often requires transpositions, reshapes, new axis (`None`) and numerical axis arguments sprinkled everywhere. It can be hard to get these right and in the end it's often hard to make sense of the written model.\n",
    "\n",
    "## Expanding the role of dims\n",
    "\n",
    "Now we are introducing an experimental :mod:`pymc.dims` module that allows users to define data, distributions, and math operations that respect dim semantics, following Xarray as closely as possible. \n",
    "\n",
    "This notebook presents an example. We'll start with a model written in current PyMC style, using this synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921cb1a07f11b51f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:25.197894Z",
     "start_time": "2025-06-30T15:53:20.093896Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "seed = sum(map(ord, \"dims module\"))\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "observed_response_np = np.ones((5, 20), dtype=int)\n",
    "coords = coords = {\n",
    "    \"participant\": range(5),\n",
    "    \"trial\": range(20),\n",
    "    \"item\": range(3),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ecff83e6b09dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:25.522571Z",
     "start_time": "2025-06-30T15:53:25.393579Z"
    }
   },
   "source": [
    "This model predicts participants' categorical responses across trials by combining participant-specific item preferences (constrained to sum to zero) with shared time-varying effects, then applying a softmax to model response probabilities.\n",
    "\n",
    "Notice the need to identify axes by number rather than dimension name, and the need to use `None` to create new axes in order to specify broadcast requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91af148",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as model:\n",
    "    observed_response = pm.Data(\n",
    "        \"observed_response\", observed_response_np, dims=(\"participant\", \"trial\")\n",
    "    )\n",
    "    # Use ZeroSumNormal to avoid identifiability issues\n",
    "    participant_preference = pm.ZeroSumNormal(\n",
    "        \"participant_preference\", n_zerosum_axes=1, dims=(\"participant\", \"item\")\n",
    "    )\n",
    "\n",
    "    # Shared time effects across all participants\n",
    "    time_effects = pm.Normal(\"time_effects\", dims=(\"trial\", \"item\"))\n",
    "\n",
    "    trial_preference = pm.Deterministic(\n",
    "        \"trial_preference\",\n",
    "        participant_preference[:, None, :] + time_effects[None, :, :],\n",
    "        dims=(\"participant\", \"trial\", \"item\"),\n",
    "    )\n",
    "\n",
    "    response = pm.Categorical(\n",
    "        \"response\",\n",
    "        p=pm.math.softmax(trial_preference, axis=-1),\n",
    "        observed=observed_response,\n",
    "        dims=(\"participant\", \"trial\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa25b6d8713c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:29.819511Z",
     "start_time": "2025-06-30T15:53:25.547610Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to_graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd191bed68527806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:07.115779Z",
     "start_time": "2025-06-26T21:31:05.140898Z"
    }
   },
   "source": [
    "And here's the equivalent model using the :mod:`pymc.dims` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94964484499b163c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:29.908171Z",
     "start_time": "2025-06-30T15:53:29.845474Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymc.dims as pmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020e450cc165e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:29.997156Z",
     "start_time": "2025-06-30T15:53:29.935025Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as dmodel:\n",
    "    observed_response = pmd.Data(\n",
    "        \"observed_response\", observed_response_np, dims=(\"participant\", \"trial\")\n",
    "    )\n",
    "    participant_preference = pmd.ZeroSumNormal(\n",
    "        \"participant_preference\", core_dims=\"item\", dims=(\"participant\", \"item\")\n",
    "    )\n",
    "\n",
    "    # Shared time effects across all participants\n",
    "    time_effects = pmd.Normal(\"time_effects\", dims=(\"item\", \"trial\"))\n",
    "\n",
    "    trial_preference = pmd.Deterministic(\n",
    "        \"trial_preference\",\n",
    "        participant_preference + time_effects,\n",
    "    )\n",
    "\n",
    "    response = pmd.Categorical(\n",
    "        \"response\",\n",
    "        p=pmd.math.softmax(trial_preference, dim=\"item\"),\n",
    "        core_dims=\"item\",\n",
    "        observed=observed_response,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93cdc3ae56689a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:07.214221Z",
     "start_time": "2025-06-26T21:31:07.191541Z"
    }
   },
   "source": [
    "Note we still use the same :class:`~pymc.Model` constructor, but everything else was now defined with an equivalent function or class defined in the :mod:`pymc.dims` module.\n",
    "\n",
    "There are some notable differences:\n",
    "\n",
    "1. `ZeroSumNormal` takes a `core_dims` argument instead of `n_zerosum_axes`. This tells PyMC which of the `dims` that define the distribution are constrained to be zero-summed. All distributions that take non-scalar parameters now require a `core_dims` argument. Previously, they were assumed to be right-aligned by the user (see more in :doc:`dimensionality`). Now you don't have to worry about the order of the dimensions in your model, just their meaning!\n",
    "\n",
    "2. The `trial_preference` computation aligns dimensions for broadcasting automatically.\n",
    "\n",
    "3. The `softmax` operation specifies the `dim` argument, not the positional axis. Note: The parameter is called `dim` and not `core_dims` because we try to stay as close as possible to the Xarray API, which uses `dim` throughout. But we make an exception for distributions because they already have the `dims` argument.\n",
    "\n",
    "4. The `Categorical` observed variable, like `ZeroSumNormal`, requires a `core_dims` argument to specify which dimension corresponds to the probability vector. Previously, it was necessary to place this dimension explicitly on the rightmost axis -- not any more!\n",
    "\n",
    "5. Even though dims were not specified for either `trial_preference` or `response`, PyMC automatically infers them. \n",
    "\n",
    "The graphviz representation confirms that the results are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1a65de0af06b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:30.408038Z",
     "start_time": "2025-06-30T15:53:30.034734Z"
    }
   },
   "outputs": [],
   "source": [
    "dmodel.to_graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d93de2d86c61fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:07.373955Z",
     "start_time": "2025-06-26T21:31:07.243130Z"
    }
   },
   "source": [
    "We can also check that the models are equivalent by comparing the `logp` of each variable evaluated at the initial_point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11073d9b67a72f72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:34.534342Z",
     "start_time": "2025-06-30T15:53:30.457494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Does this work?\n",
    "model.point_logps() == dmodel.point_logps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048579ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.point_logps())\n",
    "print(dmodel.point_logps())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee981114897c7ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.349480Z",
     "start_time": "2025-06-26T21:31:07.387385Z"
    }
   },
   "source": [
    "### A brief look under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360b5f5e9e8ca1e",
   "metadata": {},
   "source": [
    "The :mod:`pymc.dims` module functionality is built on top of the experimental :mod:`pytensor.xtensor` module in PyTensor, which is the :lib:`Xarray` analogoue of the :mod:`pytensor.tensor` module you may be familiar with (see :doc:`pymc_and_pytensor`).\n",
    "\n",
    "Whereas regular distributions and math operations return :class:`pytensor.tensor.TensorVariable` objects, the corresponding functions in the :mod:`pymc.dims` module returns :class:`pytensor.xtensor.XTensorVariable` objects. These are very similar to `TensorVariable`, but they have a `dims` attribute that determines their behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1fa8ecb7309782",
   "metadata": {},
   "source": [
    "As an example, we'll create a regular `Normal` random variable with 3 elements, and perform an outer addition on them using NumPy syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bece958e432c369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:34.611874Z",
     "start_time": "2025-06-30T15:53:34.598883Z"
    }
   },
   "outputs": [],
   "source": [
    "regular_normal = pm.Normal.dist(mu=pm.math.as_tensor([0, 1, 2]), sigma=1, shape=(3,))\n",
    "regular_normal.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0aa77e31170c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:34.700430Z",
     "start_time": "2025-06-30T15:53:34.693544Z"
    }
   },
   "outputs": [],
   "source": [
    "type(regular_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77168a8c6e89de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:34.805130Z",
     "start_time": "2025-06-30T15:53:34.792870Z"
    }
   },
   "outputs": [],
   "source": [
    "outer_addition = regular_normal[:, None] + regular_normal[None, :]\n",
    "outer_addition.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95fe88c1877fbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:34.930130Z",
     "start_time": "2025-06-30T15:53:34.887799Z"
    }
   },
   "outputs": [],
   "source": [
    "pm.draw(outer_addition, random_seed=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d78e2f3984adbc",
   "metadata": {},
   "source": [
    "Here's the same operation with a dimmed `Normal` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e8417789d4c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:35.055530Z",
     "start_time": "2025-06-30T15:53:35.045241Z"
    }
   },
   "outputs": [],
   "source": [
    "dims_normal = pmd.Normal.dist(mu=pmd.math.as_xtensor([0, 1, 2], dims=(\"a\",)), sigma=1)\n",
    "dims_normal.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c30011c910370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:35.264315Z",
     "start_time": "2025-06-30T15:53:35.256071Z"
    }
   },
   "outputs": [],
   "source": [
    "type(dims_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3932d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e75f235dcf219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:35.472551Z",
     "start_time": "2025-06-30T15:53:35.465427Z"
    }
   },
   "outputs": [],
   "source": [
    "outer_addition = dims_normal + dims_normal.rename({\"a\": \"b\"})\n",
    "outer_addition.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e2a2634a0e898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:35.758679Z",
     "start_time": "2025-06-30T15:53:35.649256Z"
    }
   },
   "outputs": [],
   "source": [
    "pm.draw(outer_addition, random_seed=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c7cda782cac69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.365035095Z",
     "start_time": "2025-06-26T11:42:19.021166Z"
    }
   },
   "source": [
    "### Redundant (or implicit) dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4877e24859dfe",
   "metadata": {},
   "source": [
    "When defining deterministic operations or creating variables whose dimension are all implied by the parameters, there's no need to specify the `dims` argument, as PyMC will automatically know them.\n",
    "\n",
    "However, some users might want to specify `dims` anyway, to check that the dimensions of the variables are as expected, or as type hints for someone reading the model.\n",
    "\n",
    "PyMC allows specifying dimensions in these cases. To reduce confusion, the output will always be transposed to be aligned with the user-specified dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6031d682b88e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:35.989010Z",
     "start_time": "2025-06-30T15:53:35.965369Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords={\"a\": range(2), \"b\": range(5)}) as example:\n",
    "    x = pmd.Normal(\"x\", dims=(\"a\", \"b\"))\n",
    "    det_implicit_dims = pmd.Deterministic(\"det1\", x + 1)\n",
    "    det_explicit_dims = pmd.Deterministic(\"det2\", x + 1, dims=(\"a\", \"b\"))\n",
    "    det_transposed_dims = pmd.Deterministic(\"y\", x + 1, dims=(\"b\", \"a\"))\n",
    "\n",
    "print(f\"{det_implicit_dims.dims=}\")\n",
    "print(f\"{det_explicit_dims.dims=}\")\n",
    "print(f\"{det_transposed_dims.dims=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db657b20b447c56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.365174897Z",
     "start_time": "2025-06-26T11:42:19.389561Z"
    }
   },
   "source": [
    "This happens with `Deterministic`, `Potential` and every distribution in the `dims` module.\n",
    "Any time you specify `dims`, you will get back a variable with the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f73575a51d316a",
   "metadata": {},
   "source": [
    "Furthermore -- and unlike regular PyMC objects -- it is now valid to use ellipsis in the `dims` argument.\n",
    "As in an Xarray `transpose`, it means all the other dimensions should stay in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3597de136004f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:36.397445Z",
     "start_time": "2025-06-30T15:53:36.371682Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords={\"a\": range(2), \"b\": range(5)}) as example:\n",
    "    x = pmd.Normal(\"x\", dims=(\"a\", \"b\"))\n",
    "    det_ellipsis1 = pmd.Deterministic(\"det1\", x + 1, dims=(...,))\n",
    "    det_ellipsis2 = pmd.Deterministic(\"det2\", x + 1, dims=(..., \"a\"))\n",
    "    det_ellipsis3 = pmd.Deterministic(\"det3\", x + 1, dims=(\"b\", ...))\n",
    "\n",
    "print(f\"{det_ellipsis1.dims=}\")\n",
    "print(f\"{det_ellipsis2.dims=}\")\n",
    "print(f\"{det_ellipsis3.dims=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c563fb2eb106b",
   "metadata": {},
   "source": [
    "### What functionality is supported?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88acbfae651fe294",
   "metadata": {},
   "source": [
    "The documentation is still a work in progress, and there is no complete list of distributions and operations that are supported just yet. \n",
    "\n",
    "#### Model constructors\n",
    "\n",
    "The following PyMC model constructors are available in the `dims` module.\n",
    "\n",
    "  * :func:`~pymc.dims.Data`\n",
    "  * :func:`~pymc.dims.Deterministic`\n",
    "  * :func:`~pymc.dims.Potential`\n",
    "\n",
    "They all return :class:`pytensor.xtensor.type.XTensorVariable` objects, and either infer `dims` from the input or require the user to specify them explicitly. If they can be inferred, it is possible to transpose and use ellipsis in the `dims` argument, as described above.\n",
    "\n",
    "#### Distributions\n",
    "\n",
    "We want to offer all the existing distributions and parametrizations under the :mod:`pymc.dims` module, with the following expected API differences:\n",
    "\n",
    " * All vector arguments (and observed values) must have known dims. An error is raised otherwise.\n",
    "\n",
    " * Distributions with non-scalar inputs will require a `core_dims` argument. The meaning of the `core_dims` argument will be denoted in the docstrings of each distribution. For example, for the MvNormal, the `core_dims` are the two dimensions of the covariance matrix, one (and only one) of which must also be present in the mean parameter. The shared `core_dim` is the one that persists in the output. Sometimes the order of `core_dims` will be important!\n",
    "\n",
    " * `dims` accept ellipsis, and variables are transposed to match the user-specified `dims` argument.\n",
    "\n",
    " * `shape` and `size` cannot be provided.\n",
    "\n",
    " * The :met:`pymc.distributions.core.DimDistribution.dist` method accepts a `dims_length` argument, of the form `{dim_name: dim_length}`.\n",
    "\n",
    " * Only transforms defined in :mod:`pymc.dims.transforms` can be used with distributions from the module.\n",
    "\n",
    "#### Operations on variables\n",
    "\n",
    "Calling a PyMC distribution from the :mod:`pymc.dims` module returns an :class:`pytensor.xtensor.type.XTensorVariable`.\n",
    "\n",
    "The expectation is that every :class:`xarray.DataArray` method in Xarray should have an equivalent version for XTensorVariables. So if you can do `x.diff(dim=\"a\")` in Xarray, you should be able to do `x.diff(dim=\"a\")` with XTensorVariables as well.\n",
    "\n",
    "In addition, many numerical operations are available in the :mod:`pymc.dims.math` module, which provides a superset of `ufuncs` functions found in Xarray (like `exp`). It also includes submodules such as `linalg` that provide counterpart to libraries like :lib:`Xarray_einstats` (such as `linalg.solve`).\n",
    "\n",
    "Finally, functions that are available at the module level in Xarray (like `concat`) are also available in the :mod:`pymc.dims` namespace.\n",
    "\n",
    "To facilitate adoption of these functions and methods, we try to follow the same API used by Xarray and related packages. However, some methods or keyword arguments won't be supported explicitly (like `.isel`, more on that at the end), in which case an informative error or warning will be raised.\n",
    "\n",
    "If you find an API difference or some missing functionality, and no reason is provided, please [open an issue](https://github.com/pymc-devs/pymc/issues) to let us know (after checking nobody has done it already).\n",
    "\n",
    "In the meantime, the next section provides some hints on how to make use of pre-existing functionality in PyMC/PyTensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a94f5939872e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.365484979Z",
     "start_time": "2025-06-26T11:42:19.577389Z"
    }
   },
   "source": [
    "### Combining dims module with the old API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a253e168df7d982",
   "metadata": {},
   "source": [
    "Because the `dims` module is more recent in does not offer all the functionality of the old API.\n",
    "\n",
    "You can always combine the two APIs by converting the variables explicitly. To obtain a regular non-dimmed variable from a dimmed variable, you can use :attr:`pytensor.xtensor.type.XTensorVariable.values` (like in Xarray) or the more verbose :func:`pymc.dims.as_xtensor`.\n",
    "\n",
    "Otherwise, if you try to pass an XTensorVariable to a function or distribution that does not support it, you will usually see an error like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd12e65aa9739c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:36.555888Z",
     "start_time": "2025-06-30T15:53:36.548186Z"
    }
   },
   "outputs": [],
   "source": [
    "mu = pmd.math.as_xtensor([0, 1, 2], dims=(\"a\",))\n",
    "try:\n",
    "    pm.Normal.dist(mu=mu)\n",
    "except TypeError as e:\n",
    "    print(f\"{e.__class__.__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b094a6cdd0bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:36.767188Z",
     "start_time": "2025-06-30T15:53:36.745075Z"
    }
   },
   "outputs": [],
   "source": [
    "pm.Normal.dist(mu=x.values).type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca88323e2529a57",
   "metadata": {},
   "source": [
    "The order of the dimensions follows that specified in the :attr:`pytensor.xtensor.type.XTensorVariable.dims` property. To be sure this matches the expectation you can use a :met:`pytensor.xtensor.type.XTensorVariable.transpose` operation to reorder the dimensions before converting to a regular variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e256f247d3bd9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.365732804Z",
     "start_time": "2025-06-26T11:42:19.755931Z"
    }
   },
   "source": [
    "Conversely, if you try to pass a regular variable to a function or distribution that expects an XTensorVariable, you will see an error like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f7161ca2d22e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:36.879320Z",
     "start_time": "2025-06-30T15:53:36.868282Z"
    }
   },
   "outputs": [],
   "source": [
    "mu = pm.math.as_tensor([0, 1, 2], name=\"mu_x\")\n",
    "try:\n",
    "    x = pmd.Normal.dist(mu=mu)\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__.__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507c0a8e76447fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.365847399Z",
     "start_time": "2025-06-26T11:42:19.826864Z"
    }
   },
   "source": [
    "Which you can avoid by explicitly converting the variable to a dimmed variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50363261fe81df6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:37.226477Z",
     "start_time": "2025-06-30T15:53:37.204756Z"
    }
   },
   "outputs": [],
   "source": [
    "pmd.Normal.dist(mu=pmd.as_xtensor(mu, dims=(\"a\",))).type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b13e9b5cd20a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.365953097Z",
     "start_time": "2025-06-26T11:42:19.885598Z"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "To put this to practice, let us write a model that uses the :class:`~pymc.LKJCholeskyCov` distribution, which at the time of writing is not yet available in the :mod:`pymc.dims` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae78e1b95f5198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:38.236088Z",
     "start_time": "2025-06-30T15:53:37.672791Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords={\"core1\": range(3), \"core2\": range(3), \"batch\": range(5)}) as mixed_api_model:\n",
    "    chol, _, _ = pm.LKJCholeskyCov(\n",
    "        \"chol\",\n",
    "        eta=1,\n",
    "        n=3,\n",
    "        sd_dist=pm.Exponential.dist(1),\n",
    "    )\n",
    "    chol_xr = pmd.as_xtensor(chol, dims=(\"core1\", \"core2\"))\n",
    "\n",
    "    mu = pmd.Normal(\"mu\", dims=(\"batch\", \"core1\"))\n",
    "    y = pmd.MvNormal(\n",
    "        \"y\",\n",
    "        mu,\n",
    "        chol=chol_xr,\n",
    "        core_dims=(\"core1\", \"core2\"),\n",
    "    )\n",
    "\n",
    "print(f\"{chol_xr.dims=}\")\n",
    "print(f\"{mu.dims=}\")\n",
    "print(f\"{y.dims=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0dd0fea61f8862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.366068103Z",
     "start_time": "2025-06-26T11:42:19.946909Z"
    }
   },
   "source": [
    "Note that we had to pass a \"regular\" Exponential distribution to the :class:`~pymc.LKJCholeskyCov` constructor. In general all distribution \"factories\" which are parametrized by unnamed distributions created with the :met:`pymc.distributions.distribution.Distribution.dist` method, won't work with variables created with the :mod:`pymc.dims` module.\n",
    "\n",
    "Overtime we hope to implement such functionality directly in the :mod:`pymc.dims` module, but for now you have to be aware of this limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464ae49ff629660",
   "metadata": {},
   "source": [
    "## Case study: a splines model comes ashore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5150d0fa3017d9b9",
   "metadata": {},
   "source": [
    "### A model begging for vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c622bbde1c675",
   "metadata": {},
   "source": [
    "The model below was presented by a user in a [bug report](). There may have been other reasons for approaching the model in this way, and it may have deviated from the user application for the purposes of providing a reproducible example for the bug report.\n",
    "\n",
    "With the disclaimer out of the way, we can say that the model is written in a way that is highly suboptimal. Specifically it misses (or actively breaks) many opportunities for vectorization. Seasoned Python programmers will know that python loops are SLOW, and that tools like NumPy provide a way to escape from this handicap.\n",
    "\n",
    "PyMC code is not exactly NumPy, for starters it uses a lazy symbolic computation library (PyTensor) that generates compiled code on demand. But it very much likes to be given NumPy-like code. To begin with these graphs are much smaller and therefore easier to reason about (in fact the original bug could only be triggered for graphs with more than 500 nodes). Secondly, NumPy-like graphs naturally translate to vectorized CPU and GPU code, which you want at the end of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f696e6bf17d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:39.748768Z",
     "start_time": "2025-06-30T15:53:39.740157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simulated data of some spline\n",
    "N = 500\n",
    "x_np = np.linspace(0, 10, N)\n",
    "y_obs_np = np.piecewise(\n",
    "    x_np,\n",
    "    [x_np <= 3, (x_np > 3) & (x_np <= 7), x_np > 7],\n",
    "    [lambda x: 0.5 * x, lambda x: 1.5 + 0.2 * (x - 3), lambda x: 2.3 - 0.1 * (x - 7)],\n",
    ")\n",
    "y_obs_np += rng.normal(0, 0.2, size=N)  # Add noise\n",
    "\n",
    "# Artificial groups\n",
    "groups = [0, 1, 2]\n",
    "group_idx_np = np.random.choice(groups, size=N)\n",
    "\n",
    "n_knots = 50\n",
    "knots_np = np.linspace(0, 10, num=n_knots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8519125d17f0c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:40.367851Z",
     "start_time": "2025-06-30T15:53:39.854962Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as non_vectorized_splines_model:\n",
    "    sigma_beta0 = pm.HalfNormal(\"sigma_beta0\", sigma=10)\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=1)\n",
    "\n",
    "    # Create likelihood per group\n",
    "    for gr in groups:\n",
    "        idx = group_idx_np == gr\n",
    "\n",
    "        beta0 = pm.HalfNormal(f\"beta0_{gr}\", sigma=sigma_beta0)\n",
    "        z = pm.Normal(f\"z_{gr}\", mu=0, sigma=2, shape=n_knots)\n",
    "\n",
    "        delta_factors = pm.math.softmax(z)\n",
    "        slope_factors = 1 - pm.math.cumsum(delta_factors[:-1])\n",
    "        spline_slopes = pm.math.stack(\n",
    "            [beta0] + [beta0 * slope_factors[i] for i in range(n_knots - 1)]\n",
    "        )\n",
    "        beta = pm.Deterministic(\n",
    "            f\"beta_{gr}\",\n",
    "            pm.math.concatenate(([beta0], pm.math.diff(spline_slopes))),\n",
    "        )\n",
    "\n",
    "        hinge_terms = [pm.math.maximum(0, x_np[idx] - knot) for knot in knots_np]\n",
    "        X = pm.math.stack([hinge_terms[i] for i in range(n_knots)], axis=1)\n",
    "\n",
    "        mu = pm.math.dot(X, beta)\n",
    "\n",
    "        pm.Normal(f\"y_{gr}\", mu=mu, sigma=sigma, observed=y_obs_np[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56dcb51a07a5b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:40.700094Z",
     "start_time": "2025-06-30T15:53:40.463806Z"
    }
   },
   "outputs": [],
   "source": [
    "non_vectorized_splines_model.to_graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d16a1bef908f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:52.686637Z",
     "start_time": "2025-06-26T21:31:52.509222Z"
    }
   },
   "source": [
    "### Old style vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8feda2a4b6bb25d",
   "metadata": {},
   "source": [
    "With some work we can rewrite the model to use vectorized operations.\n",
    "\n",
    "We'll introduce `coords` and :func:`~pymc.Data` to make the model more self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c129be4eadafaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:40.891985Z",
     "start_time": "2025-06-30T15:53:40.820861Z"
    }
   },
   "outputs": [],
   "source": [
    "coords = {\n",
    "    \"group\": range(3),\n",
    "    \"knots\": range(n_knots),\n",
    "    \"obs\": range(N),\n",
    "}\n",
    "with pm.Model(coords=coords) as vectorized_splines_model:\n",
    "    x = pm.Data(\"x\", x_np, dims=\"obs\")\n",
    "    y_obs = pm.Data(\"y_obs\", y_obs_np, dims=\"obs\")\n",
    "\n",
    "    knots = pm.Data(\"knots\", knots_np, dims=\"knot\")\n",
    "\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=1)\n",
    "    sigma_beta0 = pm.HalfNormal(\"sigma_beta0\", sigma=10)\n",
    "    beta0 = pm.HalfNormal(\"beta_0\", sigma=sigma_beta0, dims=\"group\")\n",
    "    z = pm.Normal(\"z\", dims=(\"group\", \"knot\"))\n",
    "\n",
    "    delta_factors = pm.math.softmax(z, axis=-1)  # (groups, knot)\n",
    "    slope_factors = 1 - pm.math.cumsum(delta_factors[:, :-1], axis=-1)  # (groups, knot-1)\n",
    "    spline_slopes = pm.math.concatenate(\n",
    "        [beta0[:, None], beta0[:, None] * slope_factors], axis=-1\n",
    "    )  # (groups, knot-1)\n",
    "    beta = pm.math.concatenate(\n",
    "        [beta0[:, None], pm.math.diff(spline_slopes, axis=-1)], axis=-1\n",
    "    )  # (groups, knot)\n",
    "\n",
    "    beta = pm.Deterministic(\"beta\", beta, dims=(\"group\", \"knot\"))\n",
    "\n",
    "    X = pm.math.maximum(0, x[:, None] - knots[None, :])  # (n, knot)\n",
    "    mu = (X * beta[group_idx_np]).sum(-1)  # ((n, knots) * (n, knots)).sum(-1) = (n,)\n",
    "    y = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y_obs, dims=\"obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94fa06a1190a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:41.063986Z",
     "start_time": "2025-06-30T15:53:40.980450Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorized_splines_model.to_graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98bbe7f2e17783a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:32:15.059906Z",
     "start_time": "2025-06-26T21:32:15.024281Z"
    }
   },
   "source": [
    "The graphviz does not show the whole complexity of the models. The biggest problem lied in the multiple list comprehensions used in the origin model. Every iteration extends the computational graph (basically unrolling the python loop), which becomes unfeasible for PyMC to handle.\n",
    "\n",
    "The use of 3 likelihood and sets of priors is otherwise fine and can make more sense in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8f4ee3fd9f2a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:41.192185Z",
     "start_time": "2025-06-30T15:53:41.162347Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytensor.graph import FunctionGraph\n",
    "\n",
    "non_vectorized_splines_model_graph = FunctionGraph(\n",
    "    outputs=non_vectorized_splines_model.observed_RVs, clone=False\n",
    ")\n",
    "vectorized_model_nodes = len(\n",
    "    FunctionGraph(outputs=vectorized_splines_model.basic_RVs, clone=False).apply_nodes\n",
    ")\n",
    "print(f\"Non-vectorized model has {len(non_vectorized_splines_model_graph.apply_nodes)} nodes\")\n",
    "print(f\"Vectorized model has {vectorized_model_nodes} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532b2ec365bfecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:32:17.432572Z",
     "start_time": "2025-06-26T21:32:17.415088Z"
    }
   },
   "source": [
    "### Vectorization with dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0e3dcfd9eb94a",
   "metadata": {},
   "source": [
    "It is however not trivial to write (or translate into) vectorized code like this. It takes some time to grok the patterns and there are many pain-points. We reckon that the conversion between the first and second model took at least one hour, including debugging and testing that the models were indeed equivalent.\n",
    "\n",
    "We believe that the :mod:`pymc.dims` module will facilitate writing efficient vectorized code. So let's try and do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33471edc920db393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:41.689900Z",
     "start_time": "2025-06-30T15:53:41.666926Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as dims_splines_model:\n",
    "    x = pmd.Data(\"x\", x_np, dims=\"obs\")\n",
    "    y_obs = pmd.Data(\"y_obs\", y_obs_np, dims=\"obs\")\n",
    "    knots = pmd.Data(\"knots\", knots_np, dims=(\"knot\",))\n",
    "    group_idx = pmd.math.as_xtensor(group_idx_np, dims=(\"obs\",))\n",
    "\n",
    "    sigma = pmd.HalfCauchy(\"sigma\", beta=1)\n",
    "    sigma_beta0 = pmd.HalfNormal(\"sigma_beta0\", sigma=10)\n",
    "    beta0 = pmd.HalfNormal(\"beta_0\", sigma=sigma_beta0, dims=(\"group\",))\n",
    "    z = pmd.Normal(\"z\", dims=(\"group\", \"knot\"))\n",
    "\n",
    "    delta_factors = pmd.math.softmax(z, dim=\"knot\")\n",
    "    slope_factors = 1 - delta_factors.isel(knot=slice(None, -1)).cumsum(\"knot\")\n",
    "    spline_slopes = pmd.concat([beta0, beta0 * slope_factors], dim=\"knot\")\n",
    "    beta = pm.Deterministic(\"beta\", pmd.concat([beta0, spline_slopes.diff(\"knot\")], dim=\"knot\"))\n",
    "\n",
    "    X = pmd.math.maximum(0, x - knots)\n",
    "    mu = (X * beta.isel(group=group_idx)).sum(\"knot\")\n",
    "    y = pmd.Normal(\"y\", mu=mu, sigma=sigma, observed=y_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55cf90d737dcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:42.362928Z",
     "start_time": "2025-06-30T15:53:42.151483Z"
    }
   },
   "outputs": [],
   "source": [
    "dims_splines_model.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9dd4669342ff9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:42.797760Z",
     "start_time": "2025-06-30T15:53:42.794464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comment out if you want to wait a long while for the results\n",
    "# non_vectorized_splines_model.point_logps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86701f276baaa7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:44.309696Z",
     "start_time": "2025-06-30T15:53:43.273978Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorized_splines_model.point_logps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c353131915cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:46.279261Z",
     "start_time": "2025-06-30T15:53:45.344064Z"
    }
   },
   "outputs": [],
   "source": [
    "dims_splines_model.point_logps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec3533ec122baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:32:29.344857Z",
     "start_time": "2025-06-26T21:32:28.811467Z"
    }
   },
   "source": [
    "## What about coordinates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20324c9f4f65d4b",
   "metadata": {},
   "source": [
    "The new xtensor variable and operations do not propagate information about coordinates, which means you cannot perform coordinate-related operations like you can in Xarray.\n",
    "This includes things like `sel`, `loc`, `drop`.\n",
    "\n",
    "While it is perhaps disappointing for someone used to Xarray, it is a necessary trade-off to allow PyMC to evaluate the model in a performant way. Just like before, PyMC uses PyTensor under the hood, which at the end of the day compiles functions down into the C (or numba or JAX) backends. None of these backends support dims or coordinates. To be able to keep using these backends, PyTensor rewrites the xtensor operations into equivalent tensor operations, which are pretty much abstract NumPy code. This is relative easy to do because it's mostly about aligning dimensions for broadcasting or indexing correctly.\n",
    "\n",
    "Rewriting coordinate-related operations into NumPy-like code is a different matter. Many such operations don't have straightforward equivalency, they are more like querying or joining a database than performing array operations.\n",
    "\n",
    "PyMC models will keep supporting the `coords` argument as a way to specify dimensions of model variables. But for modelling purposes, only the dimension names and their lengths play a role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963a53c229c04b9",
   "metadata": {},
   "source": [
    "### One final note of caution on coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c004fa7abdccf",
   "metadata": {},
   "source": [
    "When you provide coords to a PyMC model, they will be attached to any functions that returns Xarray or InferenceData objects.\n",
    "\n",
    "There is one potential issue with this. Like in Xarray it is valid to have multiple arrays with the same dims but different shapes. Some operations, like indexing or concatenating, act on this premise. This is also possible with PyMC models, and in fact we had such a case in the last example when we indexed the spline variable.\n",
    "\n",
    "After sampling, PyMC will try to reattach the coordinates to any computed variables (i.e., distributions, data or deterministics), but these might not have the right shape, or they might not be correctly aligned. \n",
    "\n",
    "We illustrate this with next model, where we have two variables with the `a` dim but different shapes, and only one matches the shape of the coordinates specified in the model. When PyMC tries to convert the results of sampling to InferenceData, it will issue a warning and refuse to propagate the original coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f3a2b70a4d77d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:46.850715Z",
     "start_time": "2025-06-30T15:53:46.750208Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords={\"a\": [-1, 0, 1]}) as m:\n",
    "    x = pmd.Normal(\"x\", dims=(\"a\",))\n",
    "    y = pmd.Deterministic(\"y\", x.isel(a=slice(1, None)))\n",
    "    assert y.dims == (\"a\",)\n",
    "\n",
    "    idata = pm.sample_prior_predictive()\n",
    "idata.prior[\"y\"].coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20137348aa4f5bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.371358319Z",
     "start_time": "2025-06-26T11:42:20.084741Z"
    }
   },
   "source": [
    "A user who wishes to retain coondinates for further analysis will have to manually specify them after sampling or to rename the intermediate dimensions to something else that has compatible coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f152cb249d1d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:47.572296Z",
     "start_time": "2025-06-30T15:53:47.486879Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords={\"a\": [-3, -2, -1], \"a*\": [-2, -1]}) as m:\n",
    "    x = pmd.Normal(\"x\", dims=(\"a\",))\n",
    "    y = pmd.Deterministic(\"y\", x.isel(a=slice(1, None)).rename({\"a\": \"a*\"}))\n",
    "    assert y.dims == (\"a*\",)\n",
    "    # You can rename back to the original name if you need it for further operations\n",
    "    y = y.rename({\"a*\": \"a\"})\n",
    "\n",
    "    idata = pm.sample_prior_predictive(draws=1)\n",
    "idata.prior[\"y\"].coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a051144b1259fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:31:08.371499143Z",
     "start_time": "2025-06-26T11:42:20.159762Z"
    }
   },
   "source": [
    "Note that when doing advanced indexing the name of the indexed dimension can be controlled by the name of the indexing xtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87726153a7d1fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:48.186501Z",
     "start_time": "2025-06-30T15:53:48.181799Z"
    }
   },
   "outputs": [],
   "source": [
    "x.isel(a=pmd.math.as_xtensor([0, 1, 2], dims=(\"a*\",))).dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8684f-4849-4f69-a7c7-7433182358c2",
   "metadata": {},
   "source": [
    "Silent bugs can still happen if the shapes are compatible with the wrong coords as in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443e99c-8c90-40e1-8189-943e374c1387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:48.819667Z",
     "start_time": "2025-06-30T15:53:48.747097Z"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model(coords={\"a\": [1, 2, 3]}):\n",
    "    x = pmd.Normal(\"x\", dims=(\"a\",))\n",
    "    pmd.Deterministic(\"x_reversed\", x[::-1])\n",
    "    idata = pm.sample_prior_predictive(draws=1)\n",
    "idata.prior[\"x_reversed\"].coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd902d9-33fd-40d6-a66d-fc15f1064b5c",
   "metadata": {},
   "source": [
    "Whereas Xarray would flip the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d282c1a-8a30-476d-8d92-94ea9f9a6971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:53:49.345188Z",
     "start_time": "2025-06-30T15:53:49.337999Z"
    }
   },
   "outputs": [],
   "source": [
    "idata.prior[\"x\"].isel(a=slice(None, None, -1)).coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8552be-16b8-4dd0-9bdc-38df8d5609b1",
   "metadata": {},
   "source": [
    "This is a symptom of PyMC inability to reason about coords symbolically. Is not a new problem with the :mod:`pymc.dims` module, but it is made more likely because the functions from the :mod:`pymc.dims` module require and propagate dimension names everywhere. We are still working on how to work around the problem of incompatible coordinates.\n",
    "\n",
    "We remind users that :func:`~pymc.Deterministic` are never required in a model, they are just a way to request that some intermediate operations be included in the returned results. If you use them, pay extra attention to whether the model level coordinates are appropriate for the variable in the :func:`~pymc.Deterministic`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
